{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba9ddca3-3f09-40c5-b098-d4fd256a891d",
   "metadata": {},
   "source": [
    "#  **Evaluating Techniques**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767cdc2e-976f-4913-80b3-d96a49b3cf3c",
   "metadata": {},
   "source": [
    "I will discuss some of the common Machine Learning techniques to evaluate your model.\n",
    "\n",
    "*(If you would like to understand various evaluating methods then I have written another notebook on that well)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1149a11-a919-4089-ad18-3bd417c6207d",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3ebc04-c26f-46c0-b66b-1ddad7eb6de8",
   "metadata": {},
   "source": [
    "## **Preparing Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6f374e-910b-40b2-973f-c851650103c5",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b91fb43-9b8a-469f-83ec-b71d534dc2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e35668-f6bd-47f0-8782-c239b666bfb6",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "964014c8-6c1f-473e-a896-ee7b6330cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_california_housing(as_frame=True,\n",
    "                               return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44431fea-6d3a-4521-a06f-8e9d16a11c22",
   "metadata": {},
   "source": [
    "Merging the *data* and *target* values so that we can split them into *Train* and *Test* sets together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfca750-f2f2-485b-a969-72acd1065fe1",
   "metadata": {},
   "source": [
    "### Splitting the data\n",
    "***Please Note:** I will not be focusing on splitting the data in this notebook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c004caf-096b-40bb-972e-ce9818fcac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41f524f-5ac8-488a-bf30-c8959bef98a1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d537dd42-aeca-42c7-83f5-1ae05dde9681",
   "metadata": {},
   "source": [
    "## **Preprocessing the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ab6340-5573-4103-931c-de00feddd79b",
   "metadata": {},
   "source": [
    "Let's quickly look at the our data and see if what kind of data are we dealing with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b0ce31d-ab44-4b29-bac6-440a6f0fe70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   MedInc      20640 non-null  float64\n",
      " 1   HouseAge    20640 non-null  float64\n",
      " 2   AveRooms    20640 non-null  float64\n",
      " 3   AveBedrms   20640 non-null  float64\n",
      " 4   Population  20640 non-null  float64\n",
      " 5   AveOccup    20640 non-null  float64\n",
      " 6   Latitude    20640 non-null  float64\n",
      " 7   Longitude   20640 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f706b8fd-9eca-4e1b-beb3-0946b65e8cb6",
   "metadata": {},
   "source": [
    "As we can see there are no categorical values, so we just need to prepare our data with some numerical transformation. We could easily combine our model and all the preprocessing steps into one step using a `pipeline`. But for the sake of simplicity let's just create pre-processing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a968a04-bdc4-4d8e-8257-59a321a174aa",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56ad6cbf-93e2-4ae9-9c38-0cb428e6bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1f96d0-decd-42cf-a457-7cf56e2a0469",
   "metadata": {},
   "source": [
    "### Creating a pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6b5ed8a-0b3e-4953-a273-03d82878bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7a7fc0-ebe5-4da4-8ef9-963bb5456a82",
   "metadata": {},
   "source": [
    "### Pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07af41b8-f23a-4250-9c44-67ec73b85bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = preprocessing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25f3671-5f6f-41cb-98e5-6036b6394e82",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec67363-0d1c-48dd-aa1b-a321231df884",
   "metadata": {},
   "source": [
    "## **Preparing a simple regression model**\n",
    "*(For the purpose of this notebook, we will use a simple Linear Regression Model)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bfab21-89bd-42f1-b76a-01a9b3d134cb",
   "metadata": {},
   "source": [
    "### Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5205035f-6edb-45a9-8aaa-8344785ecf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113af77f-bbbf-46f1-adf8-de050caa3528",
   "metadata": {},
   "source": [
    "### Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaf1de88-5b6d-40fc-b278-a55160927d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490cbc3d-0a62-45c0-b05b-d548fd7c3779",
   "metadata": {},
   "source": [
    "### Fitting the model to our pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2a07793-93b1-43f8-af42-14e6bf8a9497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dfcc1e-af98-4839-bed5-37557c56ac9c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c1f871-4890-4ea7-ade2-dfa99cdab197",
   "metadata": {},
   "source": [
    "## **Let's get our preditctions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eafc9fb-1587-4fb1-b691-b6cbc58918f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lin_reg.predict(X_train_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2493dbac-c6ac-4e20-a4ee-8882eaefbbaf",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0bfb6e-b997-48d4-b1aa-a7bb74b935b3",
   "metadata": {},
   "source": [
    "# **Cross Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bbe987-dee4-49b7-9472-6281cf25425f",
   "metadata": {},
   "source": [
    "- The general idea is to split the training set into smaller training sets and a validation set, then train your models against the smaller training set and evaluate them against the validation set. \n",
    "- Scikit-Learn provides with a method called `cross_validate` for this purpose *([link to Scikit-Learn Page](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate))*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61726ccc-f4de-46f0-bf73-bb281f9d6d66",
   "metadata": {},
   "source": [
    "## *`cross_validate` :*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b8a3ad-7d4e-41e4-bed5-d84ba56165bf",
   "metadata": {},
   "source": [
    "- It is used in order to understand the score on both *test* and *train* sets and also to see *fit* and *score* times\n",
    "- You could provide multiple scoring parameters\n",
    "\n",
    "*To run cross-validation for a single metric evalution, you can use `cross_val_score`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11924770-1211-446e-aff5-be02fa7b5fa1",
   "metadata": {},
   "source": [
    "#### Some parameters which are offered are:\n",
    "- estimator: Estimator object implementing 'fit'\n",
    "    - The object to use to fit the data\n",
    "- scoring: str, callable, list, tuple, or dict, default=*None*\n",
    "    - Strategy to evaluate the performance of the cross-validated model on the test *(validation)* set\n",
    "    - You can find the complete list of values [here](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)\n",
    "- cv: int, *default=None*\n",
    "    - How many folds do you want to create of your data set\n",
    "    - None, to use the default 5-fold cross validation\n",
    "- return_train_score: bool, *default=False*\n",
    "    - Whether to include train scores\n",
    "    - Computing training scores is used to get insights on how different parameter settings impact the overfitting/underfitting trade-off\n",
    "    - Computing scores on the training set can be computationally expensive and is not strictly required to select parameters that yeild the best generalization performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b42ebc-ed5a-4626-80c6-c317fe80c7d9",
   "metadata": {},
   "source": [
    "#### Implementing `cross_validate` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ed014aa-311b-4191-93b3-6c659826103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scores = cross_validate(estimator=lin_reg,\n",
    "                       X=X_train_prepared,\n",
    "                       y=y_train,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=10,\n",
    "                       return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db4f1caa-b2dc-4c97-9c46-8f780f33a303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00579262, 0.00482678, 0.00386262, 0.00386119, 0.0038588 ,\n",
       "        0.00384784, 0.00579071, 0.00425839, 0.00303721, 0.00286961]),\n",
       " 'score_time': array([0.00096607, 0.        , 0.        , 0.0009656 , 0.        ,\n",
       "        0.00096488, 0.00096583, 0.00099468, 0.00096631, 0.00101519]),\n",
       " 'test_score': array([-0.46912055, -0.57023278, -0.52267997, -0.48319985, -0.54304536,\n",
       "        -0.49879977, -0.47454501, -0.54283267, -0.54130712, -0.55059256]),\n",
       " 'train_score': array([-0.52340385, -0.51216672, -0.51747305, -0.52183985, -0.51516999,\n",
       "        -0.52019339, -0.52281692, -0.51562862, -0.5154741 , -0.51435056])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791ab193-291d-46c4-8b3a-207915a2f203",
   "metadata": {},
   "source": [
    "#### `cross_validate` returns few things:\n",
    "- fit_time\n",
    "    - The time for fitting the estimator on the train set for each cv split\n",
    "- score_time\n",
    "    - The time for scoring the estimator on the test set for each cv split\n",
    "    - Time for scoring on the train set is not included even if `return_train_score` is set to `True`\n",
    "- test_score\n",
    "    - The score array for test scores on each cv split\n",
    "    - Suffix `_score` in `test_score` changes to a specific metric like `test_r2` or `test_auc` if there are multiple scoring metrics in the scoring parameter\n",
    "- train_score\n",
    "    - The score array for train scores on each cv split\n",
    "    - This is available only if `return_train_score` parameter is `True`\n",
    "    - Suffix _score in `train_score` changes to a specific metric like `train_r2` or `train_auc` if there are multiple scoring metrics in the scoring parameter\n",
    "- estimator\n",
    "    - The estimator objects for each cv split\n",
    "    - This is available only if `return_estimator` parameter is set to `True`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43315051-3ff6-4cd5-a8b3-132acb869f93",
   "metadata": {},
   "source": [
    "If you noticed, we set `scoring` as `neg_mean_squared_error` which doesn't provide RMSE by default. We can easily change it to the RMSE by using a `sqrt` fucntion from `numpy`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff85adaf-fed2-4429-a061-2d47c33b04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_scores = np.sqrt(-scores['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a615abf8-37d6-4aa5-8e1f-a9e9b81f3d05",
   "metadata": {},
   "source": [
    "Since we set `cv` as 10, we have 10 different scores. Another advantage of `cross_validation` is that you can calculate variance in your scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f5e4e97-9cfa-45de-9569-1a627b63983a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.720472599387967\n",
      "Std Dev: 0.023554156653336395\n"
     ]
    }
   ],
   "source": [
    "mean_score = np.mean(rmse_scores)\n",
    "std_score = np.std(rmse_scores)\n",
    "\n",
    "print(f'Mean: {mean_score}')\n",
    "print(f'Std Dev: {std_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45252b93-1756-49e5-9599-481d3f731357",
   "metadata": {},
   "source": [
    "## *`cross_val_score` :*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadd435c-daa2-416e-b4a0-78e881e73d03",
   "metadata": {},
   "source": [
    "- We can use `cross_val_score` instead of `cross_validate` if we just want to run cross-validation for a single metric evaluation\n",
    "- We can't specify multiple metrics for evaluation\n",
    "- It only returns a dict of test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37effd7d-c57b-4297-99a8-130d4c0abc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(estimator=lin_reg,\n",
    "                           X=X_train_prepared,\n",
    "                           y=y_train,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdf1ff65-467e-466e-8836-f63ea1563ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.46912055, -0.57023278, -0.52267997, -0.48319985, -0.54304536,\n",
       "       -0.49879977, -0.47454501, -0.54283267, -0.54130712, -0.55059256])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e923c740-79f7-499e-81ab-c761d2aa5233",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
