{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15237989-ecf3-4025-998d-c8ec0a834077",
   "metadata": {},
   "source": [
    "# **Fine Tuning Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f21bcf5-8664-4f2e-b092-acad2693b96e",
   "metadata": {},
   "source": [
    "In order to get the optimal solution, we need to fine tune our model with differnt values of the hyperparameters. This can be daunting task, fortunately *Scikit-Learn* provides with libraries which help us to do that. The general idea is to try to out multiple values *(either from a given set of values or from a range of values)* and compare the scores for all those values, then choose the one which has the best score out of all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd63a381-c562-4e06-8e5a-9156c736b0d9",
   "metadata": {},
   "source": [
    "I will discuss 2 main concepts for fine tuning your model:\n",
    "- ## `GridSearchCV`\n",
    "- ## `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7741e8a3-362f-496a-8254-eb4f46a09b15",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aac9ac-928f-4ff4-9690-aa01f52fbc3f",
   "metadata": {},
   "source": [
    "## **Preparing Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b5628b-ea6c-47ad-baab-3d417d145ac4",
   "metadata": {},
   "source": [
    "## Fetch the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2574ebb-397e-4b22-88e4-f53a16e99b77",
   "metadata": {},
   "source": [
    "We use `fetch_openml` to get the *MNIST* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d429094-33ba-4652-83d7-0aac0f2d14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml(name='mnist_784', \n",
    "                     version=1)\n",
    "\n",
    "X = mnist['data']\n",
    "y = mnist['target'].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce686540-c640-4c44-b7ce-fd6af5ed0d34",
   "metadata": {},
   "source": [
    "## Splitting the dataset into *Training* and *Test* dataset\n",
    "By default *MNIST* dataset is shuffled into training and test dataset and arranged. First 60000 rows are the *Training* set and remaing are *Test* set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d80ca23-1e4c-4edd-83e6-96565ac364f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:60000]\n",
    "X_test = X[60000:]\n",
    "y_train = y[:60000]\n",
    "y_test = y[60000:]\n",
    "\n",
    "X_train_subset = X_train[:1000]\n",
    "y_train_subset = y_train[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1cde52-2710-499e-8be5-e6171dc97c90",
   "metadata": {},
   "source": [
    "## **Base line model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8913bbf-9c04-4bf6-af6d-1d4307193078",
   "metadata": {},
   "source": [
    "We will use a *Support Vector Machine* for our practice, but you can use any model you prefer. To be more specific, we will be using `SVC` with different kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e745345-256d-4056-bbc1-639f3467fa49",
   "metadata": {},
   "source": [
    "## *Training on a subset of the training set and checking the performance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0abba9c3-f1e0-47c1-8907-ade946633f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a3a2a4-2bef-4b15-b65b-72245dca7333",
   "metadata": {},
   "source": [
    "#### Training the model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afdba506-945a-4e5a-b05c-56da3413a333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = SVC()\n",
    "svm_clf.fit(X_train_subset, y_train_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d2f4e8-2365-45ab-8e4f-f2c21d6d4dde",
   "metadata": {},
   "source": [
    "#### Measuring Performance :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119c66db-ad1b-4957-8a89-1a9507852dfc",
   "metadata": {},
   "source": [
    "Now let's look at the performance of this model using `accuracy_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b76fc5ee-770b-4fd9-9f92-8435f1aeac68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy Score: 98.2%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = svm_clf.predict(X_train_subset)\n",
    "acc_scr_baseline = accuracy_score(y_train_subset, y_pred)\n",
    "print(f'Baseline Accuracy Score: {round(acc_scr_baseline*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb66642-2c36-48cb-9e37-5770e27c2fb8",
   "metadata": {},
   "source": [
    "As we can see that even without any fine tuning the general model performance pretty well with an accuracy score of 98.2%. Keep in mind we haven't trained the model with the entire set. Let's try to do that before we proceed ahead and see if the performance does drop and we really need to fine tune the model. If not, we can use another model for our practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc31fb-0564-43e7-8dee-5b765aaa6d3b",
   "metadata": {},
   "source": [
    "## *Training on the complete set and checking the performance*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48b2fc7-d899-44c3-bd23-f3049b9dec3f",
   "metadata": {},
   "source": [
    "#### Training the model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e66bcbc-3dd3-41de-b4d8-8bc2d60b6412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = SVC()\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d6180f-f050-4875-ae36-d9345bc57b7f",
   "metadata": {},
   "source": [
    "#### Measuring Performance :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b18e6b56-c438-4e77-bf05-d291ad69808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy Score (Complete): 98.99%\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm_clf.predict(X_train)\n",
    "acc_scr_baseline_complete = accuracy_score(y_train, y_pred)\n",
    "print(f'Baseline Accuracy Score (Complete): {round(acc_scr_baseline_complete*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c451ae0-bd14-4327-84a1-54dfa5463d89",
   "metadata": {},
   "source": [
    "***Please Note:** This process may take pretty long since we are using the entire training set instead of the subset*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacad409-c13c-49e3-a2d6-db23f2d97a8d",
   "metadata": {},
   "source": [
    "~As we can see, the accuracy score does drop. So we can fine tune the model on the subset *(in order to save time)* and then use the tweaked model to see if gained any performance boost on the entire training set.~\n",
    "\n",
    "The accuracy score infact increases when we provide more training data to the model. We can still fine tune the model but for this exercise let's look at a model where we can see a significant performance boost after the fine tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce50b5ca-7e46-4cfd-adce-179f8d383691",
   "metadata": {},
   "source": [
    "## **Trying out Linear Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73cd660-d8fb-4734-8355-b9d5761c8070",
   "metadata": {},
   "source": [
    "## Implementing `LinearSVC` Model and checking its performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512b0f27-f78b-4f61-902c-6d93cae5c78b",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ca32a2e-e817-4e42-892b-e77c809f368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1083a0e1-ef87-431c-94d8-04b50f4a01e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python39\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Accuracy Score: 86.81%\n"
     ]
    }
   ],
   "source": [
    "lin_svc = LinearSVC()\n",
    "lin_svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lin_svc.predict(X_train)\n",
    "acc_scr_lin_svc = accuracy_score(y_train, y_pred)\n",
    "print(f'LinearSVC Accuracy Score: {round(acc_scr_lin_svc*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b793a7ca-692d-4876-9a6f-bf317a7efd2a",
   "metadata": {},
   "source": [
    "The baseline perfomance measure is not that bad, but bad enough that we can see improvement when we fine tune the model. So we will proceed with `LinearSVC` model.\n",
    "\n",
    "***Please Note:** The purpose of this notebook is not to find the most optimal solution, but to go throught the exercise of fine tuning the model*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d32049-f4a4-4ff9-9ebb-19dc96bb0536",
   "metadata": {},
   "source": [
    "## Before we proceed to the fine-tuning, let's quickly create a pipeline with pre-processing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f999219-1982-4b57-9642-806e07daed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lin_svc', LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7ff130-c936-492c-b77a-825abcad56ea",
   "metadata": {},
   "source": [
    "## **Grid Search CV**\n",
    "We will be using `GridSearchCV` from *Scikit-Learn* package for this\n",
    "\n",
    "*[Link to the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7db49d-6a15-46ae-b000-e873fde64eea",
   "metadata": {},
   "source": [
    "## *The idea behind `GridSearchCV` is :*\n",
    "- We provide a list of hyperparameters *(`param_distribution`)* for the model to go through\n",
    "- The model then goes through all the combinations and generates a score for each combination *(each dictionary)*\n",
    "- It then selects the combination which has the highest score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512380b1-4661-4a00-9c69-9dc5d31e7a8d",
   "metadata": {},
   "source": [
    "## *Understanding the hyperparameters first*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c765513-d57d-4634-aee0-d396662bd4be",
   "metadata": {},
   "source": [
    "In order to create a `param_distribution`, we need to first understand the various hyperparameters of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7f651e-e0bb-4296-8f90-df4f66c92b6b",
   "metadata": {},
   "source": [
    "#### `LinearSVC` hyperparameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b44dbd-e48c-4a54-b76f-799921ec1924",
   "metadata": {},
   "source": [
    "Quickly looking at the [document](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) for `LinearSVC` we can see that it provides quite a lot of hyperparameters, but let's focus on some of them here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd44f617-6425-4145-b10c-781ecf37f4b9",
   "metadata": {},
   "source": [
    "- penalty: {'l1', 'l2'}\n",
    "- tol: float, default=1e-4\n",
    "- C: float, default=1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fef0bb-cb13-45ac-a1c7-87cf1b85c569",
   "metadata": {},
   "source": [
    "## *Creating the `param_distribution` for our `GridSearchCV`*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564d210e-314f-4d81-b0b6-1989c1ab7900",
   "metadata": {},
   "source": [
    "A `param_distribution` is of dictionary type or a list of dictionaries. Let's start with individual dictionaries and then we can create a list of them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac8980-2aa0-453f-9853-80d17ba411bc",
   "metadata": {},
   "source": [
    "In order to get the key for your dictionary, we can use `get_params().keys()` on our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eae7900-790c-4cf0-9e04-a8c34f7ed668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'scaler', 'lin_svc', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'lin_svc__C', 'lin_svc__class_weight', 'lin_svc__dual', 'lin_svc__fit_intercept', 'lin_svc__intercept_scaling', 'lin_svc__loss', 'lin_svc__max_iter', 'lin_svc__multi_class', 'lin_svc__penalty', 'lin_svc__random_state', 'lin_svc__tol', 'lin_svc__verbose'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "441c8341-f1d4-4cf2-9de6-0d97c17a61e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribution = [\n",
    "    {\n",
    "        'lin_svc__C': [1, 10, 50],\n",
    "        'lin_svc__penalty': ['l2'],\n",
    "        'lin_svc__tol': [1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5d48b-9f2d-4dba-a556-dce8f6421e8e",
   "metadata": {},
   "source": [
    "## **Implementing `GridSearchCV` :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c34b00bd-b507-4e28-9694-0bd81e5512f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf,\n",
    "                          param_grid=param_distribution,\n",
    "                           verbose=2,\n",
    "                          cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afebf18a-8748-4f51-a7f2-e48ff8cfabcb",
   "metadata": {},
   "source": [
    "Implementing `GridSearchCV` on the subset of the training set, to reduce the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d70b44a-ceeb-40aa-95b4-955dfb9b7791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] END lin_svc__C=1, lin_svc__penalty=l2, lin_svc__tol=0.01; total time=   0.4s\n",
      "[CV] END lin_svc__C=1, lin_svc__penalty=l2, lin_svc__tol=0.01; total time=   0.4s\n",
      "[CV] END lin_svc__C=1, lin_svc__penalty=l2, lin_svc__tol=0.01; total time=   0.4s\n",
      "[CV] END lin_svc__C=1, lin_svc__penalty=l2, lin_svc__tol=0.001; total time=   0.7s\n",
      "[CV] END lin_svc__C=1, lin_svc__penalty=l2, lin_svc__tol=0.001; total time=   0.6s\n",
      "[CV] END lin_svc__C=1, lin_svc__penalty=l2, lin_svc__tol=0.001; total time=   0.5s\n",
      "[CV] END lin_svc__C=1, lin_svc__penalty=l2, lin_svc__tol=0.0001; total time=   1.0s\n",
      "[CV] END lin_svc__C=1, lin_svc__penalty=l2, lin_svc__tol=0.0001; total time=   0.9s\n",
      "[CV] END lin_svc__C=1, lin_svc__penalty=l2, lin_svc__tol=0.0001; total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python39\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END lin_svc__C=1, lin_svc__penalty=l2, lin_svc__tol=1e-05; total time=   1.5s\n",
      "[CV] END lin_svc__C=1, lin_svc__penalty=l2, lin_svc__tol=1e-05; total time=   1.2s\n",
      "[CV] END lin_svc__C=1, lin_svc__penalty=l2, lin_svc__tol=1e-05; total time=   1.0s\n",
      "[CV] END lin_svc__C=10, lin_svc__penalty=l2, lin_svc__tol=0.01; total time=   0.4s\n",
      "[CV] END lin_svc__C=10, lin_svc__penalty=l2, lin_svc__tol=0.01; total time=   0.4s\n",
      "[CV] END lin_svc__C=10, lin_svc__penalty=l2, lin_svc__tol=0.01; total time=   0.3s\n",
      "[CV] END lin_svc__C=10, lin_svc__penalty=l2, lin_svc__tol=0.001; total time=   0.7s\n",
      "[CV] END lin_svc__C=10, lin_svc__penalty=l2, lin_svc__tol=0.001; total time=   0.7s\n",
      "[CV] END lin_svc__C=10, lin_svc__penalty=l2, lin_svc__tol=0.001; total time=   0.5s\n",
      "[CV] END lin_svc__C=10, lin_svc__penalty=l2, lin_svc__tol=0.0001; total time=   1.0s\n",
      "[CV] END lin_svc__C=10, lin_svc__penalty=l2, lin_svc__tol=0.0001; total time=   0.9s\n",
      "[CV] END lin_svc__C=10, lin_svc__penalty=l2, lin_svc__tol=0.0001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python39\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END lin_svc__C=10, lin_svc__penalty=l2, lin_svc__tol=1e-05; total time=   1.4s\n",
      "[CV] END lin_svc__C=10, lin_svc__penalty=l2, lin_svc__tol=1e-05; total time=   1.4s\n",
      "[CV] END lin_svc__C=10, lin_svc__penalty=l2, lin_svc__tol=1e-05; total time=   1.0s\n",
      "[CV] END lin_svc__C=50, lin_svc__penalty=l2, lin_svc__tol=0.01; total time=   0.4s\n",
      "[CV] END lin_svc__C=50, lin_svc__penalty=l2, lin_svc__tol=0.01; total time=   0.3s\n",
      "[CV] END lin_svc__C=50, lin_svc__penalty=l2, lin_svc__tol=0.01; total time=   0.3s\n",
      "[CV] END lin_svc__C=50, lin_svc__penalty=l2, lin_svc__tol=0.001; total time=   0.7s\n",
      "[CV] END lin_svc__C=50, lin_svc__penalty=l2, lin_svc__tol=0.001; total time=   0.6s\n",
      "[CV] END lin_svc__C=50, lin_svc__penalty=l2, lin_svc__tol=0.001; total time=   0.5s\n",
      "[CV] END lin_svc__C=50, lin_svc__penalty=l2, lin_svc__tol=0.0001; total time=   1.0s\n",
      "[CV] END lin_svc__C=50, lin_svc__penalty=l2, lin_svc__tol=0.0001; total time=   1.0s\n",
      "[CV] END lin_svc__C=50, lin_svc__penalty=l2, lin_svc__tol=0.0001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python39\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END lin_svc__C=50, lin_svc__penalty=l2, lin_svc__tol=1e-05; total time=   1.6s\n",
      "[CV] END lin_svc__C=50, lin_svc__penalty=l2, lin_svc__tol=1e-05; total time=   1.3s\n",
      "[CV] END lin_svc__C=50, lin_svc__penalty=l2, lin_svc__tol=1e-05; total time=   1.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('lin_svc', LinearSVC())]),\n",
       "             param_grid=[{'lin_svc__C': [1, 10, 50], 'lin_svc__penalty': ['l2'],\n",
       "                          'lin_svc__tol': [0.01, 0.001, 0.0001, 1e-05]}],\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_subset = X_train[:1000]\n",
    "y_train_subset = y_train[:1000]\n",
    "\n",
    "grid_search.fit(X_train_subset, y_train_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d32d3748-3f72-4257-a6fb-4aea053d9b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('lin_svc', LinearSVC(C=1, tol=0.001))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b68799-990e-48ab-8064-7e571b68a6c4",
   "metadata": {},
   "source": [
    "Using the best estimator, we will train the trainind data and see its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5c0457a-3da9-448b-84f6-ecf9d996abbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python39\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('lin_svc', LinearSVC(C=1, tol=0.001))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03df7ec6-9eb1-4020-b5d4-458459b37145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LinearSVC Accuracy Score: 92.08%\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search.best_estimator_.predict(X_train)\n",
    "acc_scr_lin_svc_best = accuracy_score(y_train, y_pred)\n",
    "print(f'Best LinearSVC Accuracy Score: {round(acc_scr_lin_svc_best*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a5ec6c-595e-4cd3-99f3-9c750caae164",
   "metadata": {},
   "source": [
    "As we can see that we were able to increase the accuracy score to 92.08% just playing tweaking some parameters. We could apply more options or tweak other parameters as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cbb167-5be8-4229-93f7-5273b08328ad",
   "metadata": {},
   "source": [
    "## **Ramdomized Search CV**\n",
    "We will be using `RandomizedSearchCV` from *Scikit-Learn* package for this\n",
    "\n",
    "*[Link to the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91422250-e5c2-4370-b198-cfed5691c41a",
   "metadata": {},
   "source": [
    "Similar to `GridSearchCV` we provide the param distribution and scores are calculated for the possible combinations. The only difference is that in `GridSearchCV` we define the combinations and do training of the model whereas in RandomizedSearchCV the model selects the combinations randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fa5af3-03aa-411f-8c6c-a52be89250c8",
   "metadata": {},
   "source": [
    "## *Initializing the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3234fc51-4227-4769-ba01-6e7b6fd69525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lin_svc', LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dd8824-1f63-45d8-b6a3-dbee2a682271",
   "metadata": {},
   "source": [
    "## *Generating Parameter Distribution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7168c856-64c6-4a49-9f1a-b5fb647e25c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'scaler', 'lin_svc', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'lin_svc__C', 'lin_svc__class_weight', 'lin_svc__dual', 'lin_svc__fit_intercept', 'lin_svc__intercept_scaling', 'lin_svc__loss', 'lin_svc__max_iter', 'lin_svc__multi_class', 'lin_svc__penalty', 'lin_svc__random_state', 'lin_svc__tol', 'lin_svc__verbose'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34476e61-1d6a-49ad-a542-dec113cde108",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribution = [\n",
    "    {\n",
    "        'lin_svc__C': [x for x in range(1, 10)],\n",
    "        'lin_svc__penalty': ['l2'],\n",
    "        'lin_svc__tol': [1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20d78c8d-030f-4eaf-900f-64c610bc3b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=clf,\n",
    "                                  param_distributions=param_distribution,\n",
    "                                  cv=3,\n",
    "                                  verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576b4da7-f956-4482-9ada-48192bc52418",
   "metadata": {},
   "source": [
    "## *Fitting the Random Search model to the subset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e754961-186a-43a9-9b64-0a937a6aa5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END lin_svc__C=6, lin_svc__penalty=l2, lin_svc__tol=0.0001; total time=   1.1s\n",
      "[CV] END lin_svc__C=6, lin_svc__penalty=l2, lin_svc__tol=0.0001; total time=   1.0s\n",
      "[CV] END lin_svc__C=6, lin_svc__penalty=l2, lin_svc__tol=0.0001; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python39\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END lin_svc__C=4, lin_svc__penalty=l2, lin_svc__tol=1e-05; total time=   1.6s\n",
      "[CV] END lin_svc__C=4, lin_svc__penalty=l2, lin_svc__tol=1e-05; total time=   1.3s\n",
      "[CV] END lin_svc__C=4, lin_svc__penalty=l2, lin_svc__tol=1e-05; total time=   1.1s\n",
      "[CV] END lin_svc__C=2, lin_svc__penalty=l2, lin_svc__tol=0.001; total time=   0.7s\n",
      "[CV] END lin_svc__C=2, lin_svc__penalty=l2, lin_svc__tol=0.001; total time=   0.7s\n",
      "[CV] END lin_svc__C=2, lin_svc__penalty=l2, lin_svc__tol=0.001; total time=   0.6s\n",
      "[CV] END lin_svc__C=9, lin_svc__penalty=l2, lin_svc__tol=0.01; total time=   0.4s\n",
      "[CV] END lin_svc__C=9, lin_svc__penalty=l2, lin_svc__tol=0.01; total time=   0.4s\n",
      "[CV] END lin_svc__C=9, lin_svc__penalty=l2, lin_svc__tol=0.01; total time=   0.4s\n",
      "[CV] END lin_svc__C=1, lin_svc__penalty=l2, lin_svc__tol=0.01; total time=   0.4s\n",
      "[CV] END lin_svc__C=1, lin_svc__penalty=l2, lin_svc__tol=0.01; total time=   0.3s\n",
      "[CV] END lin_svc__C=1, lin_svc__penalty=l2, lin_svc__tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python39\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END lin_svc__C=1, lin_svc__penalty=l2, lin_svc__tol=1e-05; total time=   1.6s\n",
      "[CV] END lin_svc__C=1, lin_svc__penalty=l2, lin_svc__tol=1e-05; total time=   1.2s\n",
      "[CV] END lin_svc__C=1, lin_svc__penalty=l2, lin_svc__tol=1e-05; total time=   1.1s\n",
      "[CV] END lin_svc__C=4, lin_svc__penalty=l2, lin_svc__tol=0.001; total time=   0.7s\n",
      "[CV] END lin_svc__C=4, lin_svc__penalty=l2, lin_svc__tol=0.001; total time=   0.7s\n",
      "[CV] END lin_svc__C=4, lin_svc__penalty=l2, lin_svc__tol=0.001; total time=   0.5s\n",
      "[CV] END lin_svc__C=6, lin_svc__penalty=l2, lin_svc__tol=0.001; total time=   0.7s\n",
      "[CV] END lin_svc__C=6, lin_svc__penalty=l2, lin_svc__tol=0.001; total time=   0.6s\n",
      "[CV] END lin_svc__C=6, lin_svc__penalty=l2, lin_svc__tol=0.001; total time=   0.5s\n",
      "[CV] END lin_svc__C=5, lin_svc__penalty=l2, lin_svc__tol=0.01; total time=   0.4s\n",
      "[CV] END lin_svc__C=5, lin_svc__penalty=l2, lin_svc__tol=0.01; total time=   0.4s\n",
      "[CV] END lin_svc__C=5, lin_svc__penalty=l2, lin_svc__tol=0.01; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python39\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END lin_svc__C=2, lin_svc__penalty=l2, lin_svc__tol=1e-05; total time=   1.5s\n",
      "[CV] END lin_svc__C=2, lin_svc__penalty=l2, lin_svc__tol=1e-05; total time=   1.3s\n",
      "[CV] END lin_svc__C=2, lin_svc__penalty=l2, lin_svc__tol=1e-05; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python39\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                             ('lin_svc', LinearSVC())]),\n",
       "                   param_distributions=[{'lin_svc__C': [1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                                                        9],\n",
       "                                         'lin_svc__penalty': ['l2'],\n",
       "                                         'lin_svc__tol': [0.01, 0.001, 0.0001,\n",
       "                                                          1e-05]}],\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X_train_subset, y_train_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fe97307-59c7-4b5c-a724-cf8850373573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('lin_svc', LinearSVC(C=1, tol=1e-05))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d8d796-ee0c-41ba-9eb9-2454842872d6",
   "metadata": {},
   "source": [
    "Fitting the best estimator to the entire training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6d9bd6-09c5-4f2d-82da-6f2578e496a7",
   "metadata": {},
   "source": [
    "## *Training on the entire set and checking performance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9eea1d5-6ccf-4be3-9caa-04e7aa2f7a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python39\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('lin_svc', LinearSVC(C=1, tol=1e-05))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6b9aff0-9bc3-4f84-a607-f9ac1125cd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rnd Src Accuracy Score: 92.11%\n"
     ]
    }
   ],
   "source": [
    "y_pred = random_search.best_estimator_.predict(X_train)\n",
    "rnd_src_acc_src = accuracy_score(y_train, y_pred)\n",
    "print(f'Rnd Src Accuracy Score: {round(rnd_src_acc_src*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbe22cf-87a1-4a22-9d15-1165cf6515ea",
   "metadata": {},
   "source": [
    "As we can see that the *Accuracy Score* increased to 92.11% after the fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0843fdd-8f3d-4a9d-b810-51f86feff6d9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9bc2d9-dfe2-472d-adcb-dff78926c8bc",
   "metadata": {},
   "source": [
    "## **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033ce075-f022-4b8c-9679-7781203b08be",
   "metadata": {},
   "source": [
    "Fine tuning a model is an important step in your Machine Learning process. Before we fine tune a model, we should narrow down to few models first using the performance metrics and then fine tune them in order to gain a performance boost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
